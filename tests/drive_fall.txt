2022-07-05 13:33:57.363574: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/melodic/lib:/home/dangield/aruco/install/lib:/home/dangield/opencv3/install/lib
2022-07-05 13:33:57.363611: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Reset
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten (Flatten)            (None, 20)                0         
_________________________________________________________________
dense (Dense)                (None, 50)                1050      
_________________________________________________________________
dense_1 (Dense)              (None, 10)                510       
_________________________________________________________________
flatten_1 (Flatten)          (None, 10)                0         
=================================================================
Total params: 1,560
Trainable params: 1,560
Non-trainable params: 0
_________________________________________________________________
2022-07-05 13:34:00.333472: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2022-07-05 13:34:00.333514: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dgieldow): /proc/driver/nvidia/version does not exist
2022-07-05 13:34:00.334100: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Training for 30000 steps ...
Reset
/home/dangield/.local/lib/python3.6/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  warnings.warn('`Model.state_updates` will be removed in a future version. '
   111/30000: episode: 1, duration: 2.007s, episode steps: 111, steps per second:  55, episode reward: -319.314, mean reward: -2.877 [-20.000, 87.312], mean action: 4.369 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
   217/30000: episode: 2, duration: 0.904s, episode steps: 106, steps per second: 117, episode reward: -620.713, mean reward: -5.856 [-20.000, 39.566], mean action: 4.472 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
   322/30000: episode: 3, duration: 2.782s, episode steps: 105, steps per second:  38, episode reward: -92.721, mean reward: -0.883 [-20.000, 91.433], mean action: 3.924 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
   403/30000: episode: 4, duration: 1.141s, episode steps:  81, steps per second:  71, episode reward: -320.566, mean reward: -3.958 [-35.117, 20.653], mean action: 4.309 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
   637/30000: episode: 5, duration: 1.307s, episode steps: 234, steps per second: 179, episode reward: -1518.372, mean reward: -6.489 [-20.000, 24.959], mean action: 4.389 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
   759/30000: episode: 6, duration: 1.503s, episode steps: 122, steps per second:  81, episode reward: -682.085, mean reward: -5.591 [-20.000, 16.778], mean action: 4.533 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
   957/30000: episode: 7, duration: 4.252s, episode steps: 198, steps per second:  47, episode reward: -856.868, mean reward: -4.328 [-20.000, 21.177], mean action: 4.727 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  1194/30000: episode: 8, duration: 0.611s, episode steps: 237, steps per second: 388, episode reward: -1918.491, mean reward: -8.095 [-20.000, 12.505], mean action: 4.726 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  1321/30000: episode: 9, duration: 0.768s, episode steps: 127, steps per second: 165, episode reward: -964.915, mean reward: -7.598 [-20.000, 39.855], mean action: 4.079 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  1415/30000: episode: 10, duration: 0.941s, episode steps:  94, steps per second: 100, episode reward: -492.981, mean reward: -5.244 [-20.000, 73.625], mean action: 4.351 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  1535/30000: episode: 11, duration: 2.451s, episode steps: 120, steps per second:  49, episode reward: -171.847, mean reward: -1.432 [-20.000, 29.271], mean action: 4.925 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  1577/30000: episode: 12, duration: 1.063s, episode steps:  42, steps per second:  40, episode reward: -227.427, mean reward: -5.415 [-20.000, 17.336], mean action: 4.786 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  1736/30000: episode: 13, duration: 3.701s, episode steps: 159, steps per second:  43, episode reward: -1175.177, mean reward: -7.391 [-38.254, 14.107], mean action: 4.723 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  1919/30000: episode: 14, duration: 3.482s, episode steps: 183, steps per second:  53, episode reward: -753.113, mean reward: -4.115 [-20.000, 20.229], mean action: 4.503 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  1996/30000: episode: 15, duration: 2.234s, episode steps:  77, steps per second:  34, episode reward: -110.496, mean reward: -1.435 [-20.000, 53.547], mean action: 4.143 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  2054/30000: episode: 16, duration: 0.997s, episode steps:  58, steps per second:  58, episode reward: -148.748, mean reward: -2.565 [-20.000, 19.778], mean action: 4.431 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  2129/30000: episode: 17, duration: 1.023s, episode steps:  75, steps per second:  73, episode reward: -331.249, mean reward: -4.417 [-20.000, 66.461], mean action: 4.533 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  2230/30000: episode: 18, duration: 1.780s, episode steps: 101, steps per second:  57, episode reward: -413.043, mean reward: -4.090 [-20.000, 55.596], mean action: 4.911 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  2272/30000: episode: 19, duration: 0.761s, episode steps:  42, steps per second:  55, episode reward: -189.167, mean reward: -4.504 [-20.000,  1.930], mean action: 4.762 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  2434/30000: episode: 20, duration: 2.760s, episode steps: 162, steps per second:  59, episode reward: -561.571, mean reward: -3.466 [-43.447, 26.140], mean action: 4.278 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  2494/30000: episode: 21, duration: 0.754s, episode steps:  60, steps per second:  80, episode reward: -211.452, mean reward: -3.524 [-20.000, 33.422], mean action: 4.800 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  2675/30000: episode: 22, duration: 1.351s, episode steps: 181, steps per second: 134, episode reward: -1051.658, mean reward: -5.810 [-20.000, 62.334], mean action: 4.287 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  2916/30000: episode: 23, duration: 3.720s, episode steps: 241, steps per second:  65, episode reward: -1503.725, mean reward: -6.240 [-43.267, 19.647], mean action: 4.656 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  2941/30000: episode: 24, duration: 0.539s, episode steps:  25, steps per second:  46, episode reward:  9.157, mean reward:  0.366 [-20.000, 97.058], mean action: 3.720 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  3037/30000: episode: 25, duration: 0.642s, episode steps:  96, steps per second: 150, episode reward: -412.583, mean reward: -4.298 [-20.000, 100.621], mean action: 4.688 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  3148/30000: episode: 26, duration: 1.910s, episode steps: 111, steps per second:  58, episode reward: -563.917, mean reward: -5.080 [-20.000, 22.963], mean action: 4.288 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  3389/30000: episode: 27, duration: 3.250s, episode steps: 241, steps per second:  74, episode reward: -1676.805, mean reward: -6.958 [-48.608, 14.256], mean action: 3.788 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  3462/30000: episode: 28, duration: 1.260s, episode steps:  73, steps per second:  58, episode reward: -294.913, mean reward: -4.040 [-20.000, 14.218], mean action: 3.836 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  3534/30000: episode: 29, duration: 1.267s, episode steps:  72, steps per second:  57, episode reward: -260.393, mean reward: -3.617 [-20.000, 10.321], mean action: 3.778 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  3598/30000: episode: 30, duration: 0.326s, episode steps:  64, steps per second: 196, episode reward: -338.571, mean reward: -5.290 [-20.000, 74.795], mean action: 5.031 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  3695/30000: episode: 31, duration: 2.200s, episode steps:  97, steps per second:  44, episode reward: -196.036, mean reward: -2.021 [-20.000, 47.864], mean action: 4.093 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  3799/30000: episode: 32, duration: 0.742s, episode steps: 104, steps per second: 140, episode reward: -471.220, mean reward: -4.531 [-20.000, 106.083], mean action: 4.308 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  3860/30000: episode: 33, duration: 1.177s, episode steps:  61, steps per second:  52, episode reward: -259.996, mean reward: -4.262 [-20.000, 37.003], mean action: 4.246 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  4027/30000: episode: 34, duration: 2.685s, episode steps: 167, steps per second:  62, episode reward: -562.626, mean reward: -3.369 [-20.000, 26.478], mean action: 4.539 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  4148/30000: episode: 35, duration: 2.295s, episode steps: 121, steps per second:  53, episode reward: -349.126, mean reward: -2.885 [-20.000, 14.816], mean action: 3.802 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  4227/30000: episode: 36, duration: 1.324s, episode steps:  79, steps per second:  60, episode reward: -465.554, mean reward: -5.893 [-20.000, 26.852], mean action: 3.481 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  4368/30000: episode: 37, duration: 1.769s, episode steps: 141, steps per second:  80, episode reward: -582.645, mean reward: -4.132 [-20.000, 12.312], mean action: 4.333 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  4477/30000: episode: 38, duration: 1.364s, episode steps: 109, steps per second:  80, episode reward: -471.297, mean reward: -4.324 [-20.000, 28.255], mean action: 4.229 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  4533/30000: episode: 39, duration: 0.599s, episode steps:  56, steps per second:  93, episode reward: -164.777, mean reward: -2.942 [-20.000, 26.482], mean action: 3.946 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  4607/30000: episode: 40, duration: 1.516s, episode steps:  74, steps per second:  49, episode reward: -172.423, mean reward: -2.330 [-20.000, 70.987], mean action: 3.554 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  4797/30000: episode: 41, duration: 4.555s, episode steps: 190, steps per second:  42, episode reward: -443.984, mean reward: -2.337 [-20.000, 19.843], mean action: 4.089 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  4881/30000: episode: 42, duration: 0.982s, episode steps:  84, steps per second:  86, episode reward: -205.332, mean reward: -2.444 [-20.000, 63.436], mean action: 4.905 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
  4946/30000: episode: 43, duration: 0.691s, episode steps:  65, steps per second:  94, episode reward: -118.793, mean reward: -1.828 [-20.000, 143.703], mean action: 3.846 [0.000, 9.000],  loss: --, mae: --, mean_q: --, mean_eps: --
Reset
/home/dangield/.local/lib/python3.6/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  warnings.warn('`Model.state_updates` will be removed in a future version. '
  5103/30000: episode: 44, duration: 1.983s, episode steps: 157, steps per second:  79, episode reward: -994.844, mean reward: -6.337 [-20.000, 22.795], mean action: 4.312 [0.000, 9.000],  loss: 37.777322, mae: 0.780640, mean_q: 0.805083, mean_eps: 0.848455
Reset
  5344/30000: episode: 45, duration: 3.409s, episode steps: 241, steps per second:  71, episode reward: -1141.450, mean reward: -4.736 [-20.000, 21.629], mean action: 4.942 [0.000, 9.000],  loss: 37.124290, mae: 0.776234, mean_q: 0.855770, mean_eps: 0.843310
Reset
  5485/30000: episode: 46, duration: 1.240s, episode steps: 141, steps per second: 114, episode reward: -1194.753, mean reward: -8.473 [-20.000, 15.645], mean action: 4.794 [0.000, 9.000],  loss: 46.772442, mae: 0.796369, mean_q: 0.882495, mean_eps: 0.837580
Reset
  5564/30000: episode: 47, duration: 2.036s, episode steps:  79, steps per second:  39, episode reward: -81.783, mean reward: -1.035 [-20.000, 20.666], mean action: 3.962 [0.000, 9.000],  loss: 43.395318, mae: 0.801037, mean_q: 0.901694, mean_eps: 0.834280
Reset
  5690/30000: episode: 48, duration: 4.098s, episode steps: 126, steps per second:  31, episode reward: -238.436, mean reward: -1.892 [-20.000, 19.758], mean action: 3.714 [0.000, 9.000],  loss: 37.865527, mae: 0.775799, mean_q: 0.916382, mean_eps: 0.831205
Reset
  5733/30000: episode: 49, duration: 1.199s, episode steps:  43, steps per second:  36, episode reward: -53.413, mean reward: -1.242 [-20.000, 84.372], mean action: 4.605 [0.000, 9.000],  loss: 38.372525, mae: 0.780799, mean_q: 0.922339, mean_eps: 0.828670
Reset
  5810/30000: episode: 50, duration: 2.744s, episode steps:  77, steps per second:  28, episode reward: -82.651, mean reward: -1.073 [-20.000, 20.560], mean action: 4.013 [0.000, 9.000],  loss: 40.568080, mae: 0.781485, mean_q: 0.930008, mean_eps: 0.826870
Reset
  6051/30000: episode: 51, duration: 4.265s, episode steps: 241, steps per second:  57, episode reward: -1493.986, mean reward: -6.199 [-38.224, 21.567], mean action: 4.531 [0.000, 9.000],  loss: 43.086345, mae: 0.781652, mean_q: 0.933923, mean_eps: 0.822100
Reset
  6104/30000: episode: 52, duration: 0.903s, episode steps:  53, steps per second:  59, episode reward: -206.982, mean reward: -3.905 [-20.000, 24.716], mean action: 4.830 [0.000, 9.000],  loss: 42.528026, mae: 0.777215, mean_q: 0.931751, mean_eps: 0.817690
Reset
  6228/30000: episode: 53, duration: 1.727s, episode steps: 124, steps per second:  72, episode reward: -621.554, mean reward: -5.013 [-20.000, 44.245], mean action: 4.508 [0.000, 9.000],  loss: 44.923823, mae: 0.791880, mean_q: 0.951106, mean_eps: 0.815035
Reset
  6443/30000: episode: 54, duration: 6.063s, episode steps: 215, steps per second:  35, episode reward: -886.080, mean reward: -4.121 [-90.285, 17.406], mean action: 4.284 [0.000, 9.000],  loss: 38.193114, mae: 0.758641, mean_q: 0.934231, mean_eps: 0.809950
Reset
  6569/30000: episode: 55, duration: 3.085s, episode steps: 126, steps per second:  41, episode reward: -349.452, mean reward: -2.773 [-20.000, 62.511], mean action: 3.881 [0.000, 9.000],  loss: 47.860830, mae: 0.778782, mean_q: 0.936495, mean_eps: 0.804835
Reset
  6796/30000: episode: 56, duration: 4.765s, episode steps: 227, steps per second:  48, episode reward: -1163.910, mean reward: -5.127 [-20.000, 13.667], mean action: 4.789 [0.000, 9.000],  loss: 40.074291, mae: 0.768207, mean_q: 0.943485, mean_eps: 0.799540
Reset
  6823/30000: episode: 57, duration: 0.436s, episode steps:  27, steps per second:  62, episode reward: 89.030, mean reward:  3.297 [-20.000, 100.319], mean action: 5.111 [0.000, 9.000],  loss: 38.883176, mae: 0.765360, mean_q: 0.941649, mean_eps: 0.795730
Reset
  6857/30000: episode: 58, duration: 0.812s, episode steps:  34, steps per second:  42, episode reward: -131.526, mean reward: -3.868 [-20.000, 52.085], mean action: 4.176 [0.000, 9.000],  loss: 31.231405, mae: 0.742947, mean_q: 0.948673, mean_eps: 0.794815
Reset
  7093/30000: episode: 59, duration: 4.328s, episode steps: 236, steps per second:  55, episode reward: -860.723, mean reward: -3.647 [-20.000, 21.736], mean action: 4.072 [0.000, 9.000],  loss: 43.390489, mae: 0.765342, mean_q: 0.953937, mean_eps: 0.790765
Reset
  7160/30000: episode: 60, duration: 1.022s, episode steps:  67, steps per second:  66, episode reward: -100.951, mean reward: -1.507 [-20.000, 69.912], mean action: 4.806 [0.000, 9.000],  loss: 42.722813, mae: 0.758791, mean_q: 0.952572, mean_eps: 0.786220
Reset
  7257/30000: episode: 61, duration: 1.221s, episode steps:  97, steps per second:  79, episode reward: -378.952, mean reward: -3.907 [-20.000, 86.262], mean action: 5.155 [0.000, 9.000],  loss: 48.102196, mae: 0.781982, mean_q: 0.953336, mean_eps: 0.783760
Reset
  7300/30000: episode: 62, duration: 1.421s, episode steps:  43, steps per second:  30, episode reward: -30.787, mean reward: -0.716 [-20.000, 24.058], mean action: 4.698 [0.000, 9.000],  loss: 40.822096, mae: 0.749819, mean_q: 0.944782, mean_eps: 0.781660
Reset
  7327/30000: episode: 63, duration: 0.604s, episode steps:  27, steps per second:  45, episode reward: 92.580, mean reward:  3.429 [-20.000, 124.564], mean action: 3.741 [0.000, 9.000],  loss: 32.994438, mae: 0.743586, mean_q: 0.940297, mean_eps: 0.780610
Reset
  7561/30000: episode: 64, duration: 3.257s, episode steps: 234, steps per second:  72, episode reward: -1825.023, mean reward: -7.799 [-31.051, 19.384], mean action: 4.500 [0.000, 9.000],  loss: 41.941370, mae: 0.761955, mean_q: 0.933610, mean_eps: 0.776695
Reset
  7593/30000: episode: 65, duration: 0.956s, episode steps:  32, steps per second:  33, episode reward: 13.849, mean reward:  0.433 [-20.000, 38.757], mean action: 3.531 [0.000, 9.000],  loss: 31.545273, mae: 0.758572, mean_q: 0.912160, mean_eps: 0.772705
Reset
  7646/30000: episode: 66, duration: 0.964s, episode steps:  53, steps per second:  55, episode reward: -136.420, mean reward: -2.574 [-20.000, 64.666], mean action: 4.811 [0.000, 9.000],  loss: 39.729478, mae: 0.761087, mean_q: 0.924658, mean_eps: 0.771430
Reset
  7809/30000: episode: 67, duration: 2.403s, episode steps: 163, steps per second:  68, episode reward: -680.662, mean reward: -4.176 [-20.000, 67.275], mean action: 4.693 [0.000, 9.000],  loss: 44.136589, mae: 0.769942, mean_q: 0.933982, mean_eps: 0.768190
Reset
  7843/30000: episode: 68, duration: 0.851s, episode steps:  34, steps per second:  40, episode reward: 129.136, mean reward:  3.798 [-20.000, 173.210], mean action: 4.735 [0.000, 9.000],  loss: 68.193109, mae: 0.787224, mean_q: 0.940959, mean_eps: 0.765235
Reset
  8020/30000: episode: 69, duration: 5.378s, episode steps: 177, steps per second:  33, episode reward: -355.830, mean reward: -2.010 [-20.000, 18.278], mean action: 4.011 [0.000, 9.000],  loss: 46.918037, mae: 0.744227, mean_q: 0.945095, mean_eps: 0.762070
Reset
  8261/30000: episode: 70, duration: 3.574s, episode steps: 241, steps per second:  67, episode reward: -1451.342, mean reward: -6.022 [-20.000, 28.765], mean action: 4.975 [0.000, 9.000],  loss: 51.733568, mae: 0.762047, mean_q: 0.947177, mean_eps: 0.755800
Reset
  8360/30000: episode: 71, duration: 1.496s, episode steps:  99, steps per second:  66, episode reward: -336.969, mean reward: -3.404 [-20.000, 45.283], mean action: 5.162 [0.000, 9.000],  loss: 41.154463, mae: 0.750198, mean_q: 0.921101, mean_eps: 0.750700
Reset
  8384/30000: episode: 72, duration: 0.953s, episode steps:  24, steps per second:  25, episode reward: -6.027, mean reward: -0.251 [-20.000,  8.885], mean action: 3.542 [0.000, 9.000],  loss: 50.560353, mae: 0.757671, mean_q: 0.911673, mean_eps: 0.748855
Reset
  8471/30000: episode: 73, duration: 2.341s, episode steps:  87, steps per second:  37, episode reward: -131.894, mean reward: -1.516 [-20.000, 65.269], mean action: 5.299 [0.000, 9.000],  loss: 39.469458, mae: 0.749516, mean_q: 0.946697, mean_eps: 0.747190
Reset
  8569/30000: episode: 74, duration: 1.065s, episode steps:  98, steps per second:  92, episode reward: -673.971, mean reward: -6.877 [-20.000, 29.244], mean action: 4.704 [0.000, 9.000],  loss: 44.638816, mae: 0.746375, mean_q: 0.939161, mean_eps: 0.744415
Reset
  8676/30000: episode: 75, duration: 2.399s, episode steps: 107, steps per second:  45, episode reward: -162.204, mean reward: -1.516 [-20.000, 52.120], mean action: 4.533 [0.000, 9.000],  loss: 38.191366, mae: 0.759652, mean_q: 0.942572, mean_eps: 0.741340
Reset
  8763/30000: episode: 76, duration: 1.466s, episode steps:  87, steps per second:  59, episode reward: -317.143, mean reward: -3.645 [-20.000, 22.844], mean action: 2.966 [0.000, 9.000],  loss: 45.582298, mae: 0.749404, mean_q: 0.930324, mean_eps: 0.738430
Reset
  8795/30000: episode: 77, duration: 1.447s, episode steps:  32, steps per second:  22, episode reward: -0.607, mean reward: -0.019 [-20.000, 40.070], mean action: 5.281 [1.000, 9.000],  loss: 31.252807, mae: 0.721137, mean_q: 0.930199, mean_eps: 0.736645
Reset
  8837/30000: episode: 78, duration: 1.145s, episode steps:  42, steps per second:  37, episode reward: -139.242, mean reward: -3.315 [-20.000, 29.422], mean action: 4.905 [0.000, 9.000],  loss: 42.659795, mae: 0.749590, mean_q: 0.922924, mean_eps: 0.735535
Reset
  8872/30000: episode: 79, duration: 1.059s, episode steps:  35, steps per second:  33, episode reward: -38.202, mean reward: -1.091 [-20.000, 57.444], mean action: 4.571 [0.000, 9.000],  loss: 43.494046, mae: 0.728754, mean_q: 0.932301, mean_eps: 0.734380
Reset
  8937/30000: episode: 80, duration: 1.106s, episode steps:  65, steps per second:  59, episode reward: -107.175, mean reward: -1.649 [-20.000, 63.343], mean action: 4.862 [0.000, 9.000],  loss: 60.884499, mae: 0.780608, mean_q: 0.943400, mean_eps: 0.732880
Reset
  9023/30000: episode: 81, duration: 1.457s, episode steps:  86, steps per second:  59, episode reward: -194.181, mean reward: -2.258 [-20.000, 73.425], mean action: 4.314 [0.000, 9.000],  loss: 43.026337, mae: 0.750071, mean_q: 0.943204, mean_eps: 0.730615
Reset
  9061/30000: episode: 82, duration: 0.690s, episode steps:  38, steps per second:  55, episode reward: -94.560, mean reward: -2.488 [-20.000, 87.054], mean action: 5.184 [0.000, 9.000],  loss: 41.567441, mae: 0.750884, mean_q: 0.934725, mean_eps: 0.728755
Reset
  9302/30000: episode: 83, duration: 4.024s, episode steps: 241, steps per second:  60, episode reward: -989.765, mean reward: -4.107 [-20.000, 35.901], mean action: 4.577 [0.000, 9.000],  loss: 49.874016, mae: 0.763322, mean_q: 0.929147, mean_eps: 0.724570
Reset
  9506/30000: episode: 84, duration: 2.713s, episode steps: 204, steps per second:  75, episode reward: -727.390, mean reward: -3.566 [-20.000, 32.789], mean action: 5.593 [0.000, 9.000],  loss: 44.215686, mae: 0.748352, mean_q: 0.927380, mean_eps: 0.717895
Reset
  9600/30000: episode: 85, duration: 2.233s, episode steps:  94, steps per second:  42, episode reward: 85.577, mean reward:  0.910 [-20.000, 30.880], mean action: 4.447 [0.000, 9.000],  loss: 39.009373, mae: 0.731471, mean_q: 0.929335, mean_eps: 0.713425
Reset
  9841/30000: episode: 86, duration: 3.519s, episode steps: 241, steps per second:  68, episode reward: -1039.087, mean reward: -4.312 [-20.000, 72.739], mean action: 4.639 [0.000, 9.000],  loss: 48.027574, mae: 0.746682, mean_q: 0.929576, mean_eps: 0.708400
Reset
 10036/30000: episode: 87, duration: 1.914s, episode steps: 195, steps per second: 102, episode reward: -1024.069, mean reward: -5.252 [-10.030, 14.170], mean action: 4.436 [0.000, 9.000],  loss: 46.150846, mae: 0.731687, mean_q: 0.914706, mean_eps: 0.701860
Reset
 10130/30000: episode: 88, duration: 1.670s, episode steps:  94, steps per second:  56, episode reward: -63.861, mean reward: -0.679 [-20.000, 64.268], mean action: 4.830 [0.000, 9.000],  loss: 48.587027, mae: 0.746630, mean_q: 0.909357, mean_eps: 0.697525
Reset
 10209/30000: episode: 89, duration: 1.050s, episode steps:  79, steps per second:  75, episode reward: -230.198, mean reward: -2.914 [-20.000, 28.227], mean action: 4.810 [0.000, 9.000],  loss: 43.658419, mae: 0.719450, mean_q: 0.908134, mean_eps: 0.694930
Reset
 10277/30000: episode: 90, duration: 1.010s, episode steps:  68, steps per second:  67, episode reward: -51.735, mean reward: -0.761 [-20.000, 109.828], mean action: 4.971 [0.000, 9.000],  loss: 58.124238, mae: 0.756951, mean_q: 0.916343, mean_eps: 0.692725
Reset
 10330/30000: episode: 91, duration: 1.267s, episode steps:  53, steps per second:  42, episode reward: -152.676, mean reward: -2.881 [-20.000, 38.513], mean action: 3.981 [0.000, 9.000],  loss: 65.393917, mae: 0.771547, mean_q: 0.917288, mean_eps: 0.690910
Reset
 10485/30000: episode: 92, duration: 1.696s, episode steps: 155, steps per second:  91, episode reward: -644.190, mean reward: -4.156 [-20.000, 23.366], mean action: 4.994 [0.000, 9.000],  loss: 45.114494, mae: 0.719321, mean_q: 0.913631, mean_eps: 0.687790
Reset
 10575/30000: episode: 93, duration: 1.832s, episode steps:  90, steps per second:  49, episode reward: -136.376, mean reward: -1.515 [-20.000, 31.702], mean action: 4.811 [0.000, 9.000],  loss: 42.102307, mae: 0.716342, mean_q: 0.898703, mean_eps: 0.684115
Reset
 10675/30000: episode: 94, duration: 2.723s, episode steps: 100, steps per second:  37, episode reward: -266.547, mean reward: -2.665 [-20.000, 21.574], mean action: 4.170 [0.000, 9.000],  loss: 48.871733, mae: 0.729636, mean_q: 0.911842, mean_eps: 0.681265
Reset
 10783/30000: episode: 95, duration: 2.902s, episode steps: 108, steps per second:  37, episode reward: -131.438, mean reward: -1.217 [-20.000, 30.745], mean action: 3.852 [0.000, 9.000],  loss: 42.057347, mae: 0.712873, mean_q: 0.913634, mean_eps: 0.678145
Reset
 10812/30000: episode: 96, duration: 0.341s, episode steps:  29, steps per second:  85, episode reward: -91.628, mean reward: -3.160 [-20.000, 24.640], mean action: 5.000 [1.000, 9.000],  loss: 31.155243, mae: 0.686159, mean_q: 0.911055, mean_eps: 0.676090
Reset
 10902/30000: episode: 97, duration: 1.452s, episode steps:  90, steps per second:  62, episode reward: -318.669, mean reward: -3.541 [-20.000, 47.780], mean action: 5.300 [0.000, 9.000],  loss: 40.237459, mae: 0.698757, mean_q: 0.896198, mean_eps: 0.674305
Reset
 10927/30000: episode: 98, duration: 0.318s, episode steps:  25, steps per second:  79, episode reward: -51.117, mean reward: -2.045 [-20.000, 46.958], mean action: 3.760 [0.000, 8.000],  loss: 39.595426, mae: 0.702103, mean_q: 0.906100, mean_eps: 0.672580
Reset
 11003/30000: episode: 99, duration: 2.587s, episode steps:  76, steps per second:  29, episode reward: 174.038, mean reward:  2.290 [-20.000, 22.045], mean action: 3.145 [0.000, 9.000],  loss: 36.652182, mae: 0.695358, mean_q: 0.907578, mean_eps: 0.671065
Reset
 11244/30000: episode: 100, duration: 2.782s, episode steps: 241, steps per second:  87, episode reward: -1396.520, mean reward: -5.795 [-20.000, 13.216], mean action: 4.817 [0.000, 9.000],  loss: 39.801977, mae: 0.698461, mean_q: 0.896451, mean_eps: 0.666310
Reset
 11485/30000: episode: 101, duration: 2.610s, episode steps: 241, steps per second:  92, episode reward: -1219.344, mean reward: -5.060 [-20.000, 28.407], mean action: 4.473 [0.000, 9.000],  loss: 42.069471, mae: 0.703428, mean_q: 0.898511, mean_eps: 0.659080
Reset
 11654/30000: episode: 102, duration: 3.033s, episode steps: 169, steps per second:  56, episode reward: -430.454, mean reward: -2.547 [-20.000, 35.403], mean action: 4.503 [0.000, 9.000],  loss: 37.516819, mae: 0.692548, mean_q: 0.896323, mean_eps: 0.652930
Reset
 11895/30000: episode: 103, duration: 2.716s, episode steps: 241, steps per second:  89, episode reward: -1016.433, mean reward: -4.218 [-20.000, 49.663], mean action: 5.535 [0.000, 9.000],  loss: 49.347323, mae: 0.720462, mean_q: 0.884238, mean_eps: 0.646780
Reset
 11971/30000: episode: 104, duration: 2.291s, episode steps:  76, steps per second:  33, episode reward: -112.696, mean reward: -1.483 [-20.000, 15.885], mean action: 2.539 [0.000, 9.000],  loss: 37.726848, mae: 0.702952, mean_q: 0.876568, mean_eps: 0.642025
Reset
 12092/30000: episode: 105, duration: 2.721s, episode steps: 121, steps per second:  44, episode reward: -104.066, mean reward: -0.860 [-20.000, 34.687], mean action: 4.603 [0.000, 9.000],  loss: 37.483288, mae: 0.673679, mean_q: 0.888655, mean_eps: 0.639070
Reset
 12126/30000: episode: 106, duration: 0.853s, episode steps:  34, steps per second:  40, episode reward: 116.047, mean reward:  3.413 [-20.000, 57.586], mean action: 3.176 [0.000, 9.000],  loss: 43.875326, mae: 0.674898, mean_q: 0.883486, mean_eps: 0.636745
Reset
 12158/30000: episode: 107, duration: 1.297s, episode steps:  32, steps per second:  25, episode reward: 88.576, mean reward:  2.768 [-20.000, 22.017], mean action: 2.750 [0.000, 9.000],  loss: 42.695646, mae: 0.682290, mean_q: 0.889086, mean_eps: 0.635755
Reset
 12244/30000: episode: 108, duration: 2.126s, episode steps:  86, steps per second:  40, episode reward: -26.505, mean reward: -0.308 [-20.000, 30.919], mean action: 3.570 [0.000, 9.000],  loss: 42.650798, mae: 0.701362, mean_q: 0.889849, mean_eps: 0.633985
Reset
 12369/30000: episode: 109, duration: 2.088s, episode steps: 125, steps per second:  60, episode reward: -370.361, mean reward: -2.963 [-20.000, 26.011], mean action: 4.800 [0.000, 9.000],  loss: 38.678167, mae: 0.688692, mean_q: 0.888957, mean_eps: 0.630820
Reset
 12426/30000: episode: 110, duration: 1.342s, episode steps:  57, steps per second:  42, episode reward: 13.077, mean reward:  0.229 [-20.000, 100.131], mean action: 4.789 [0.000, 9.000],  loss: 32.517440, mae: 0.670802, mean_q: 0.884996, mean_eps: 0.628090
Reset
 12469/30000: episode: 111, duration: 1.476s, episode steps:  43, steps per second:  29, episode reward: 86.749, mean reward:  2.017 [-20.000, 21.370], mean action: 2.628 [0.000, 9.000],  loss: 38.841454, mae: 0.700781, mean_q: 0.885167, mean_eps: 0.626590
Reset
 12574/30000: episode: 112, duration: 1.457s, episode steps: 105, steps per second:  72, episode reward: -390.954, mean reward: -3.723 [-20.000, 33.668], mean action: 4.848 [0.000, 9.000],  loss: 36.857797, mae: 0.683484, mean_q: 0.892441, mean_eps: 0.624370
Reset
 12737/30000: episode: 113, duration: 2.944s, episode steps: 163, steps per second:  55, episode reward: -263.453, mean reward: -1.616 [-20.000, 71.269], mean action: 4.638 [0.000, 9.000],  loss: 42.389533, mae: 0.696561, mean_q: 0.889339, mean_eps: 0.620350
Reset
 12895/30000: episode: 114, duration: 1.950s, episode steps: 158, steps per second:  81, episode reward: -449.596, mean reward: -2.846 [-10.030, 25.792], mean action: 4.538 [0.000, 9.000],  loss: 39.152946, mae: 0.692462, mean_q: 0.897055, mean_eps: 0.615535
Reset
 13136/30000: episode: 115, duration: 2.889s, episode steps: 241, steps per second:  83, episode reward: -1210.947, mean reward: -5.025 [-20.000, 15.977], mean action: 5.137 [0.000, 9.000],  loss: 37.156833, mae: 0.673368, mean_q: 0.888034, mean_eps: 0.609550
Reset
 13275/30000: episode: 116, duration: 2.345s, episode steps: 139, steps per second:  59, episode reward: -358.393, mean reward: -2.578 [-20.000, 20.337], mean action: 5.022 [0.000, 9.000],  loss: 35.442393, mae: 0.666743, mean_q: 0.889602, mean_eps: 0.603850
Reset
 13447/30000: episode: 117, duration: 3.893s, episode steps: 172, steps per second:  44, episode reward: -829.038, mean reward: -4.820 [-39.619, 21.252], mean action: 4.547 [0.000, 9.000],  loss: 34.970735, mae: 0.665964, mean_q: 0.889407, mean_eps: 0.599185
Reset
 13516/30000: episode: 118, duration: 0.709s, episode steps:  69, steps per second:  97, episode reward: -233.741, mean reward: -3.388 [-10.030, 39.382], mean action: 4.812 [0.000, 9.000],  loss: 33.639662, mae: 0.661695, mean_q: 0.891170, mean_eps: 0.595570
Reset
 13601/30000: episode: 119, duration: 1.356s, episode steps:  85, steps per second:  63, episode reward: -97.560, mean reward: -1.148 [-20.000, 39.522], mean action: 4.435 [0.000, 9.000],  loss: 32.545171, mae: 0.656892, mean_q: 0.887697, mean_eps: 0.593260
Reset
 13633/30000: episode: 120, duration: 1.058s, episode steps:  32, steps per second:  30, episode reward: 42.901, mean reward:  1.341 [-20.000, 17.967], mean action: 4.188 [0.000, 9.000],  loss: 36.459119, mae: 0.669649, mean_q: 0.892228, mean_eps: 0.591505
Reset
 13719/30000: episode: 121, duration: 1.209s, episode steps:  86, steps per second:  71, episode reward: -86.837, mean reward: -1.010 [-20.000, 81.657], mean action: 5.105 [0.000, 9.000],  loss: 32.862393, mae: 0.659652, mean_q: 0.882752, mean_eps: 0.589735
Reset
 13744/30000: episode: 122, duration: 0.753s, episode steps:  25, steps per second:  33, episode reward: 56.757, mean reward:  2.270 [-20.000, 24.528], mean action: 3.720 [0.000, 8.000],  loss: 35.245822, mae: 0.661526, mean_q: 0.881488, mean_eps: 0.588070
Reset
 13985/30000: episode: 123, duration: 3.409s, episode steps: 241, steps per second:  71, episode reward: -765.109, mean reward: -3.175 [-20.000, 51.012], mean action: 4.813 [0.000, 9.000],  loss: 36.328296, mae: 0.665130, mean_q: 0.887515, mean_eps: 0.584080
Reset
 14012/30000: episode: 124, duration: 0.493s, episode steps:  27, steps per second:  55, episode reward: 59.147, mean reward:  2.191 [-21.935, 25.944], mean action: 2.407 [0.000, 6.000],  loss: 36.188783, mae: 0.641814, mean_q: 0.895558, mean_eps: 0.580060
Reset
 14072/30000: episode: 125, duration: 1.911s, episode steps:  60, steps per second:  31, episode reward: -39.805, mean reward: -0.663 [-20.000, 67.349], mean action: 3.850 [0.000, 9.000],  loss: 31.299142, mae: 0.650964, mean_q: 0.899346, mean_eps: 0.578755
Reset
 14189/30000: episode: 126, duration: 2.424s, episode steps: 117, steps per second:  48, episode reward: -117.647, mean reward: -1.006 [-20.000, 17.752], mean action: 4.308 [0.000, 9.000],  loss: 31.313726, mae: 0.653260, mean_q: 0.894294, mean_eps: 0.576100
Reset
 14307/30000: episode: 127, duration: 2.569s, episode steps: 118, steps per second:  46, episode reward: -50.603, mean reward: -0.429 [-20.000, 42.570], mean action: 4.203 [0.000, 9.000],  loss: 34.294990, mae: 0.646004, mean_q: 0.897502, mean_eps: 0.572575
Reset
 14467/30000: episode: 128, duration: 2.451s, episode steps: 160, steps per second:  65, episode reward: -245.069, mean reward: -1.532 [-20.000, 59.395], mean action: 5.550 [0.000, 9.000],  loss: 32.679928, mae: 0.648200, mean_q: 0.892482, mean_eps: 0.568405
Reset
 14708/30000: episode: 129, duration: 4.873s, episode steps: 241, steps per second:  49, episode reward: -769.552, mean reward: -3.193 [-20.000, 47.944], mean action: 5.407 [0.000, 9.000],  loss: 34.565277, mae: 0.650244, mean_q: 0.890751, mean_eps: 0.562390
Reset
 14763/30000: episode: 130, duration: 1.996s, episode steps:  55, steps per second:  28, episode reward: 59.420, mean reward:  1.080 [-20.000, 22.199], mean action: 3.400 [0.000, 9.000],  loss: 30.760400, mae: 0.612488, mean_q: 0.900358, mean_eps: 0.557950
Reset
 14815/30000: episode: 131, duration: 1.397s, episode steps:  52, steps per second:  37, episode reward: 23.292, mean reward:  0.448 [-20.000, 72.215], mean action: 4.038 [0.000, 9.000],  loss: 30.625265, mae: 0.611432, mean_q: 0.899331, mean_eps: 0.556345
Reset
 14865/30000: episode: 132, duration: 1.581s, episode steps:  50, steps per second:  32, episode reward: 21.628, mean reward:  0.433 [-20.000, 17.030], mean action: 2.360 [0.000, 9.000],  loss: 33.772792, mae: 0.616108, mean_q: 0.897149, mean_eps: 0.554815
Reset
 14926/30000: episode: 133, duration: 1.243s, episode steps:  61, steps per second:  49, episode reward: -190.384, mean reward: -3.121 [-20.000, 72.837], mean action: 5.623 [0.000, 9.000],  loss: 32.230275, mae: 0.621932, mean_q: 0.894648, mean_eps: 0.553150
Reset
 14958/30000: episode: 134, duration: 0.867s, episode steps:  32, steps per second:  37, episode reward: -7.955, mean reward: -0.249 [-20.000, 28.196], mean action: 4.031 [0.000, 9.000],  loss: 29.731531, mae: 0.626948, mean_q: 0.905743, mean_eps: 0.551755
Reset
 14985/30000: episode: 135, duration: 0.319s, episode steps:  27, steps per second:  85, episode reward: -124.592, mean reward: -4.615 [-20.000, 77.231], mean action: 3.407 [0.000, 9.000],  loss: 29.093009, mae: 0.610431, mean_q: 0.914853, mean_eps: 0.550870
Reset
 15226/30000: episode: 136, duration: 3.749s, episode steps: 241, steps per second:  64, episode reward: -727.144, mean reward: -3.017 [-20.000, 28.157], mean action: 5.801 [0.000, 9.000],  loss: 30.328897, mae: 0.625416, mean_q: 0.913918, mean_eps: 0.546850
Reset
 15467/30000: episode: 137, duration: 5.702s, episode steps: 241, steps per second:  42, episode reward: -343.625, mean reward: -1.426 [-20.000, 21.794], mean action: 4.921 [0.000, 9.000],  loss: 31.202474, mae: 0.617508, mean_q: 0.907755, mean_eps: 0.539620
Reset
 15708/30000: episode: 138, duration: 5.560s, episode steps: 241, steps per second:  43, episode reward: -539.201, mean reward: -2.237 [-20.000, 51.020], mean action: 4.905 [0.000, 9.000],  loss: 33.272821, mae: 0.625184, mean_q: 0.901686, mean_eps: 0.532390
Reset
 15776/30000: episode: 139, duration: 6.558s, episode steps:  68, steps per second:  10, episode reward: 121.825, mean reward:  1.792 [-20.000, 48.830], mean action: 2.971 [0.000, 9.000],  loss: 35.931641, mae: 0.621735, mean_q: 0.891194, mean_eps: 0.527755
Reset
 15815/30000: episode: 140, duration: 0.978s, episode steps:  39, steps per second:  40, episode reward: 46.755, mean reward:  1.199 [-20.000, 49.875], mean action: 3.949 [0.000, 9.000],  loss: 38.622505, mae: 0.642179, mean_q: 0.894760, mean_eps: 0.526150
Reset
 16056/30000: episode: 141, duration: 3.632s, episode steps: 241, steps per second:  66, episode reward: -661.041, mean reward: -2.743 [-20.000, 51.665], mean action: 5.739 [0.000, 9.000],  loss: 30.923362, mae: 0.605358, mean_q: 0.898491, mean_eps: 0.521950
Reset
 16297/30000: episode: 142, duration: 3.302s, episode steps: 241, steps per second:  73, episode reward: -1460.694, mean reward: -6.061 [-20.000, 36.791], mean action: 6.195 [0.000, 9.000],  loss: 30.109446, mae: 0.607672, mean_q: 0.891363, mean_eps: 0.514720
Reset
 16384/30000: episode: 143, duration: 2.480s, episode steps:  87, steps per second:  35, episode reward: 96.022, mean reward:  1.104 [-20.000, 63.118], mean action: 4.747 [0.000, 9.000],  loss: 32.523038, mae: 0.616327, mean_q: 0.887227, mean_eps: 0.509800
Reset
 16438/30000: episode: 144, duration: 2.765s, episode steps:  54, steps per second:  20, episode reward: 138.332, mean reward:  2.562 [-20.000, 41.409], mean action: 3.500 [0.000, 9.000],  loss: 36.602410, mae: 0.613757, mean_q: 0.886143, mean_eps: 0.507685
Reset
 16679/30000: episode: 145, duration: 2.955s, episode steps: 241, steps per second:  82, episode reward: -1392.336, mean reward: -5.777 [-20.000, 40.630], mean action: 5.797 [0.000, 9.000],  loss: 31.458519, mae: 0.601884, mean_q: 0.886581, mean_eps: 0.503260
Reset
 16854/30000: episode: 146, duration: 2.199s, episode steps: 175, steps per second:  80, episode reward: -674.842, mean reward: -3.856 [-10.030, 28.403], mean action: 5.623 [0.000, 9.000],  loss: 30.804266, mae: 0.605585, mean_q: 0.888636, mean_eps: 0.497020
Reset
 17095/30000: episode: 147, duration: 5.341s, episode steps: 241, steps per second:  45, episode reward: -350.492, mean reward: -1.454 [-20.000, 92.620], mean action: 6.324 [0.000, 9.000],  loss: 35.701250, mae: 0.620396, mean_q: 0.895174, mean_eps: 0.490780
Reset
 17172/30000: episode: 148, duration: 1.032s, episode steps:  77, steps per second:  75, episode reward: -200.784, mean reward: -2.608 [-20.000, 42.235], mean action: 5.299 [0.000, 9.000],  loss: 30.698822, mae: 0.620760, mean_q: 0.902864, mean_eps: 0.486010
Reset
 17374/30000: episode: 149, duration: 6.607s, episode steps: 202, steps per second:  31, episode reward: -305.529, mean reward: -1.513 [-20.000, 78.776], mean action: 5.188 [0.000, 9.000],  loss: 33.748324, mae: 0.621782, mean_q: 0.884528, mean_eps: 0.481825
Reset
 17615/30000: episode: 150, duration: 5.158s, episode steps: 241, steps per second:  47, episode reward: -777.100, mean reward: -3.224 [-20.000, 51.567], mean action: 5.203 [0.000, 9.000],  loss: 29.625038, mae: 0.598879, mean_q: 0.884815, mean_eps: 0.475180
Reset
 17783/30000: episode: 151, duration: 4.549s, episode steps: 168, steps per second:  37, episode reward: -182.423, mean reward: -1.086 [-20.000, 74.240], mean action: 5.827 [0.000, 9.000],  loss: 30.449875, mae: 0.606470, mean_q: 0.879169, mean_eps: 0.469045
Reset
 17854/30000: episode: 152, duration: 1.839s, episode steps:  71, steps per second:  39, episode reward:  3.162, mean reward:  0.045 [-20.000, 32.573], mean action: 4.394 [0.000, 8.000],  loss: 28.105490, mae: 0.589193, mean_q: 0.872964, mean_eps: 0.465460
Reset
 17990/30000: episode: 153, duration: 4.737s, episode steps: 136, steps per second:  29, episode reward: 30.623, mean reward:  0.225 [-20.000, 79.261], mean action: 4.471 [0.000, 9.000],  loss: 29.839369, mae: 0.590719, mean_q: 0.882162, mean_eps: 0.462355
Reset
 18181/30000: episode: 154, duration: 9.404s, episode steps: 191, steps per second:  20, episode reward: -118.056, mean reward: -0.618 [-20.000, 36.412], mean action: 5.372 [0.000, 9.000],  loss: 34.507939, mae: 0.603901, mean_q: 0.879788, mean_eps: 0.457450
Reset
 18256/30000: episode: 155, duration: 1.085s, episode steps:  75, steps per second:  69, episode reward: -163.264, mean reward: -2.177 [-20.000, 57.939], mean action: 6.227 [0.000, 9.000],  loss: 34.946642, mae: 0.591177, mean_q: 0.876237, mean_eps: 0.453460
Reset
 18316/30000: episode: 156, duration: 1.771s, episode steps:  60, steps per second:  34, episode reward: 160.384, mean reward:  2.673 [-20.000, 83.735], mean action: 3.700 [0.000, 9.000],  loss: 28.919203, mae: 0.560382, mean_q: 0.870735, mean_eps: 0.451435
Reset
 18341/30000: episode: 157, duration: 1.603s, episode steps:  25, steps per second:  16, episode reward: 87.611, mean reward:  3.504 [-20.000, 23.615], mean action: 3.720 [0.000, 9.000],  loss: 26.659147, mae: 0.555036, mean_q: 0.874231, mean_eps: 0.450160
Reset
 18363/30000: episode: 158, duration: 2.003s, episode steps:  22, steps per second:  11, episode reward: 100.072, mean reward:  4.549 [-20.000, 56.992], mean action: 4.682 [1.000, 9.000],  loss: 28.647483, mae: 0.575524, mean_q: 0.869632, mean_eps: 0.449455
Reset
 18474/30000: episode: 159, duration: 4.136s, episode steps: 111, steps per second:  27, episode reward: 36.014, mean reward:  0.324 [-20.000, 61.820], mean action: 5.541 [0.000, 9.000],  loss: 30.656110, mae: 0.586478, mean_q: 0.871269, mean_eps: 0.447460
Reset
 18715/30000: episode: 160, duration: 2.436s, episode steps: 241, steps per second:  99, episode reward: -1643.731, mean reward: -6.820 [-20.000, 13.748], mean action: 5.942 [0.000, 9.000],  loss: 31.952149, mae: 0.577275, mean_q: 0.872607, mean_eps: 0.442180
Reset
 18750/30000: episode: 161, duration: 0.483s, episode steps:  35, steps per second:  72, episode reward: -116.968, mean reward: -3.342 [-10.030,  5.265], mean action: 6.886 [0.000, 9.000],  loss: 34.068313, mae: 0.584909, mean_q: 0.865652, mean_eps: 0.438040
Reset
 18991/30000: episode: 162, duration: 6.974s, episode steps: 241, steps per second:  35, episode reward: -366.664, mean reward: -1.521 [-20.000, 23.723], mean action: 4.158 [0.000, 9.000],  loss: 30.580101, mae: 0.583012, mean_q: 0.883091, mean_eps: 0.433900
Reset
 19179/30000: episode: 163, duration: 2.734s, episode steps: 188, steps per second:  69, episode reward: -601.909, mean reward: -3.202 [-10.060, 25.247], mean action: 5.750 [0.000, 9.000],  loss: 32.541438, mae: 0.589774, mean_q: 0.877847, mean_eps: 0.427465
Reset
 19281/30000: episode: 164, duration: 1.692s, episode steps: 102, steps per second:  60, episode reward: -78.626, mean reward: -0.771 [-20.000, 112.655], mean action: 5.971 [1.000, 9.000],  loss: 34.702151, mae: 0.576440, mean_q: 0.876625, mean_eps: 0.423115
Reset
 19322/30000: episode: 165, duration: 2.037s, episode steps:  41, steps per second:  20, episode reward: 199.197, mean reward:  4.858 [-20.000, 120.702], mean action: 2.659 [0.000, 9.000],  loss: 43.849542, mae: 0.606591, mean_q: 0.872896, mean_eps: 0.420970
Reset
 19377/30000: episode: 166, duration: 1.287s, episode steps:  55, steps per second:  43, episode reward: 122.453, mean reward:  2.226 [-20.000, 44.438], mean action: 3.982 [0.000, 8.000],  loss: 31.971193, mae: 0.561006, mean_q: 0.880744, mean_eps: 0.419530
Reset
 19455/30000: episode: 167, duration: 2.635s, episode steps:  78, steps per second:  30, episode reward: 115.359, mean reward:  1.479 [-20.000, 76.840], mean action: 2.667 [0.000, 9.000],  loss: 32.202818, mae: 0.557113, mean_q: 0.875711, mean_eps: 0.417535
Reset
 19503/30000: episode: 168, duration: 0.984s, episode steps:  48, steps per second:  49, episode reward: -14.318, mean reward: -0.298 [-20.000, 55.117], mean action: 5.708 [0.000, 9.000],  loss: 39.425707, mae: 0.585765, mean_q: 0.869064, mean_eps: 0.415645
Reset
 19729/30000: episode: 169, duration: 6.038s, episode steps: 226, steps per second:  37, episode reward: 53.060, mean reward:  0.235 [-20.000, 108.534], mean action: 5.235 [0.000, 9.000],  loss: 35.366587, mae: 0.575120, mean_q: 0.872795, mean_eps: 0.411535
Reset
 19875/30000: episode: 170, duration: 3.297s, episode steps: 146, steps per second:  44, episode reward: -284.942, mean reward: -1.952 [-10.060, 39.767], mean action: 5.890 [0.000, 9.000],  loss: 31.897052, mae: 0.578175, mean_q: 0.866577, mean_eps: 0.405955
Reset
 20116/30000: episode: 171, duration: 3.846s, episode steps: 241, steps per second:  63, episode reward: -1921.774, mean reward: -7.974 [-25.309,  7.635], mean action: 5.100 [0.000, 9.000],  loss: 32.870227, mae: 0.579838, mean_q: 0.863148, mean_eps: 0.400150
Reset
 20165/30000: episode: 172, duration: 1.225s, episode steps:  49, steps per second:  40, episode reward: 30.650, mean reward:  0.626 [-10.000, 21.478], mean action: 3.510 [0.000, 9.000],  loss: 40.078357, mae: 0.597530, mean_q: 0.869924, mean_eps: 0.395800
Reset
 20406/30000: episode: 173, duration: 2.975s, episode steps: 241, steps per second:  81, episode reward: -1779.704, mean reward: -7.385 [-20.000, 56.096], mean action: 5.942 [0.000, 9.000],  loss: 34.851093, mae: 0.600060, mean_q: 0.866707, mean_eps: 0.391450
Reset
 20647/30000: episode: 174, duration: 4.164s, episode steps: 241, steps per second:  58, episode reward: -286.828, mean reward: -1.190 [-20.000, 49.645], mean action: 5.390 [0.000, 9.000],  loss: 37.738670, mae: 0.620385, mean_q: 0.859599, mean_eps: 0.384220
Reset
 20693/30000: episode: 175, duration: 1.587s, episode steps:  46, steps per second:  29, episode reward: 133.686, mean reward:  2.906 [-20.000, 17.848], mean action: 3.457 [0.000, 9.000],  loss: 31.280133, mae: 0.593934, mean_q: 0.859381, mean_eps: 0.379915
Reset
 20934/30000: episode: 176, duration: 3.578s, episode steps: 241, steps per second:  67, episode reward: -321.835, mean reward: -1.335 [-20.000, 32.340], mean action: 6.145 [0.000, 9.000],  loss: 39.905114, mae: 0.617696, mean_q: 0.852752, mean_eps: 0.375610
Reset
 21054/30000: episode: 177, duration: 2.672s, episode steps: 120, steps per second:  45, episode reward: 129.873, mean reward:  1.082 [-20.000, 68.042], mean action: 5.800 [0.000, 9.000],  loss: 34.041505, mae: 0.599548, mean_q: 0.856455, mean_eps: 0.370195
Reset
 21295/30000: episode: 178, duration: 3.301s, episode steps: 241, steps per second:  73, episode reward: -453.642, mean reward: -1.882 [-20.000, 15.037], mean action: 5.934 [0.000, 9.000],  loss: 40.015560, mae: 0.602665, mean_q: 0.854195, mean_eps: 0.364780
Reset
 21328/30000: episode: 179, duration: 1.385s, episode steps:  33, steps per second:  24, episode reward: 116.558, mean reward:  3.532 [-20.000, 29.413], mean action: 3.636 [0.000, 9.000],  loss: 35.571353, mae: 0.574833, mean_q: 0.845523, mean_eps: 0.360670
Reset
 21403/30000: episode: 180, duration: 2.411s, episode steps:  75, steps per second:  31, episode reward: 115.060, mean reward:  1.534 [-20.000, 50.040], mean action: 4.307 [0.000, 9.000],  loss: 31.130071, mae: 0.593905, mean_q: 0.845702, mean_eps: 0.359050
Reset
 21505/30000: episode: 181, duration: 2.314s, episode steps: 102, steps per second:  44, episode reward: -14.845, mean reward: -0.146 [-10.030, 33.788], mean action: 4.598 [0.000, 9.000],  loss: 33.561961, mae: 0.598183, mean_q: 0.846256, mean_eps: 0.356395
Reset
 21746/30000: episode: 182, duration: 4.165s, episode steps: 241, steps per second:  58, episode reward: -239.095, mean reward: -0.992 [-20.000, 49.301], mean action: 5.925 [0.000, 9.000],  loss: 32.283015, mae: 0.565120, mean_q: 0.837103, mean_eps: 0.351250
Reset
 21777/30000: episode: 183, duration: 0.845s, episode steps:  31, steps per second:  37, episode reward: 154.408, mean reward:  4.981 [-20.000, 58.696], mean action: 4.548 [0.000, 9.000],  loss: 28.881378, mae: 0.563289, mean_q: 0.828158, mean_eps: 0.347170
Reset
 22018/30000: episode: 184, duration: 5.490s, episode steps: 241, steps per second:  44, episode reward: -97.464, mean reward: -0.404 [-33.461, 27.132], mean action: 4.834 [0.000, 9.000],  loss: 38.338234, mae: 0.579468, mean_q: 0.841891, mean_eps: 0.343090
Reset
 22050/30000: episode: 185, duration: 0.714s, episode steps:  32, steps per second:  45, episode reward: 64.048, mean reward:  2.002 [-10.000, 24.310], mean action: 3.594 [2.000, 9.000],  loss: 32.778997, mae: 0.566013, mean_q: 0.850081, mean_eps: 0.338995
Reset
 22291/30000: episode: 186, duration: 3.765s, episode steps: 241, steps per second:  64, episode reward: -320.826, mean reward: -1.331 [-20.000, 43.925], mean action: 4.647 [0.000, 9.000],  loss: 32.720697, mae: 0.557665, mean_q: 0.845575, mean_eps: 0.334900
Reset
 22335/30000: episode: 187, duration: 1.257s, episode steps:  44, steps per second:  35, episode reward: -26.486, mean reward: -0.602 [-20.000, 12.546], mean action: 2.750 [0.000, 9.000],  loss: 23.379695, mae: 0.537447, mean_q: 0.855150, mean_eps: 0.330625
Reset
 22576/30000: episode: 188, duration: 3.409s, episode steps: 241, steps per second:  71, episode reward: -904.818, mean reward: -3.754 [-20.000, 30.651], mean action: 5.954 [0.000, 9.000],  loss: 32.175922, mae: 0.546759, mean_q: 0.844187, mean_eps: 0.326350
Reset
 22609/30000: episode: 189, duration: 0.411s, episode steps:  33, steps per second:  80, episode reward:  3.718, mean reward:  0.113 [-10.030, 28.285], mean action: 5.697 [0.000, 9.000],  loss: 32.683029, mae: 0.569404, mean_q: 0.833629, mean_eps: 0.322240
Reset
 22850/30000: episode: 190, duration: 4.591s, episode steps: 241, steps per second:  52, episode reward: -217.470, mean reward: -0.902 [-20.000, 21.188], mean action: 5.573 [0.000, 9.000],  loss: 34.929977, mae: 0.566207, mean_q: 0.842374, mean_eps: 0.318130
Reset
 22932/30000: episode: 191, duration: 1.507s, episode steps:  82, steps per second:  54, episode reward: 144.811, mean reward:  1.766 [-10.030, 115.947], mean action: 3.890 [0.000, 8.000],  loss: 35.511880, mae: 0.568132, mean_q: 0.847999, mean_eps: 0.313285
Reset
 23051/30000: episode: 192, duration: 2.220s, episode steps: 119, steps per second:  54, episode reward: -34.654, mean reward: -0.291 [-10.030, 11.773], mean action: 5.050 [0.000, 9.000],  loss: 33.266913, mae: 0.554456, mean_q: 0.841696, mean_eps: 0.310270
Reset
 23244/30000: episode: 193, duration: 3.277s, episode steps: 193, steps per second:  59, episode reward: -14.487, mean reward: -0.075 [-20.000, 77.309], mean action: 6.772 [0.000, 9.000],  loss: 33.166320, mae: 0.554544, mean_q: 0.829840, mean_eps: 0.305590
Reset
 23485/30000: episode: 194, duration: 3.909s, episode steps: 241, steps per second:  62, episode reward: -247.721, mean reward: -1.028 [-20.000, 39.996], mean action: 6.104 [0.000, 9.000],  loss: 30.557291, mae: 0.543256, mean_q: 0.828861, mean_eps: 0.299080
Reset
 23514/30000: episode: 195, duration: 0.910s, episode steps:  29, steps per second:  32, episode reward: 60.877, mean reward:  2.099 [-20.000, 42.099], mean action: 3.069 [0.000, 9.000],  loss: 47.783967, mae: 0.569611, mean_q: 0.829996, mean_eps: 0.295030
Reset
 23755/30000: episode: 196, duration: 3.909s, episode steps: 241, steps per second:  62, episode reward: -244.451, mean reward: -1.014 [-20.000, 28.645], mean action: 5.747 [0.000, 9.000],  loss: 26.703278, mae: 0.521829, mean_q: 0.823812, mean_eps: 0.290980
Reset
 23962/30000: episode: 197, duration: 4.984s, episode steps: 207, steps per second:  42, episode reward: 60.315, mean reward:  0.291 [-20.000, 27.815], mean action: 5.271 [0.000, 9.000],  loss: 30.717994, mae: 0.525104, mean_q: 0.830618, mean_eps: 0.284260
Reset
 24066/30000: episode: 198, duration: 1.763s, episode steps: 104, steps per second:  59, episode reward:  8.509, mean reward:  0.082 [-20.000, 47.745], mean action: 6.279 [0.000, 9.000],  loss: 27.061674, mae: 0.513653, mean_q: 0.828009, mean_eps: 0.279595
Reset
 24179/30000: episode: 199, duration: 1.190s, episode steps: 113, steps per second:  95, episode reward: -560.073, mean reward: -4.956 [-10.030, 20.495], mean action: 4.283 [0.000, 9.000],  loss: 30.096065, mae: 0.498981, mean_q: 0.814744, mean_eps: 0.276340
Reset
 24420/30000: episode: 200, duration: 5.264s, episode steps: 241, steps per second:  46, episode reward: -187.360, mean reward: -0.777 [-20.000, 48.047], mean action: 6.535 [0.000, 9.000],  loss: 29.720635, mae: 0.510124, mean_q: 0.800053, mean_eps: 0.271030
Reset
 24455/30000: episode: 201, duration: 0.618s, episode steps:  35, steps per second:  57, episode reward: 96.710, mean reward:  2.763 [-10.030, 67.196], mean action: 4.000 [0.000, 8.000],  loss: 27.540468, mae: 0.522236, mean_q: 0.789485, mean_eps: 0.266890
Reset
 24601/30000: episode: 202, duration: 3.270s, episode steps: 146, steps per second:  45, episode reward: 74.018, mean reward:  0.507 [-34.462, 27.147], mean action: 3.445 [0.000, 9.000],  loss: 23.582307, mae: 0.491410, mean_q: 0.803092, mean_eps: 0.264175
Reset
 24764/30000: episode: 203, duration: 3.053s, episode steps: 163, steps per second:  53, episode reward:  5.032, mean reward:  0.031 [-10.030, 31.617], mean action: 4.515 [0.000, 9.000],  loss: 26.326355, mae: 0.503642, mean_q: 0.799263, mean_eps: 0.259540
Reset
 25005/30000: episode: 204, duration: 6.268s, episode steps: 241, steps per second:  38, episode reward: 25.690, mean reward:  0.107 [-20.000, 36.772], mean action: 5.705 [0.000, 9.000],  loss: 24.182248, mae: 0.497112, mean_q: 0.813998, mean_eps: 0.253480
Reset
 25042/30000: episode: 205, duration: 0.622s, episode steps:  37, steps per second:  59, episode reward: 117.276, mean reward:  3.170 [-10.030, 19.468], mean action: 5.216 [0.000, 9.000],  loss: 21.293541, mae: 0.474037, mean_q: 0.825253, mean_eps: 0.249310
Reset
 25184/30000: episode: 206, duration: 2.116s, episode steps: 142, steps per second:  67, episode reward: 130.017, mean reward:  0.916 [-10.060, 60.678], mean action: 5.739 [0.000, 9.000],  loss: 23.199395, mae: 0.480526, mean_q: 0.809619, mean_eps: 0.246625
Reset
 25231/30000: episode: 207, duration: 1.206s, episode steps:  47, steps per second:  39, episode reward: 124.998, mean reward:  2.660 [-17.864, 30.638], mean action: 3.553 [0.000, 7.000],  loss: 19.800608, mae: 0.440539, mean_q: 0.803227, mean_eps: 0.243790
Reset
 25472/30000: episode: 208, duration: 3.440s, episode steps: 241, steps per second:  70, episode reward: -22.085, mean reward: -0.092 [-20.000, 57.895], mean action: 7.274 [0.000, 9.000],  loss: 24.176864, mae: 0.456999, mean_q: 0.802669, mean_eps: 0.239470
Reset
 25592/30000: episode: 209, duration: 2.335s, episode steps: 120, steps per second:  51, episode reward:  2.678, mean reward:  0.022 [-10.030, 11.682], mean action: 3.717 [0.000, 9.000],  loss: 23.864063, mae: 0.455405, mean_q: 0.789723, mean_eps: 0.234055
Reset
 25625/30000: episode: 210, duration: 0.614s, episode steps:  33, steps per second:  54, episode reward: 130.481, mean reward:  3.954 [-20.000, 43.475], mean action: 4.455 [0.000, 7.000],  loss: 23.887783, mae: 0.461643, mean_q: 0.807682, mean_eps: 0.231760
Reset
 25701/30000: episode: 211, duration: 1.595s, episode steps:  76, steps per second:  48, episode reward: 102.655, mean reward:  1.351 [-10.030, 29.845], mean action: 4.829 [0.000, 9.000],  loss: 29.456046, mae: 0.460587, mean_q: 0.795132, mean_eps: 0.230125
Reset
 25814/30000: episode: 212, duration: 3.055s, episode steps: 113, steps per second:  37, episode reward: 190.073, mean reward:  1.682 [-20.000, 58.749], mean action: 4.301 [0.000, 8.000],  loss: 22.442819, mae: 0.458309, mean_q: 0.799547, mean_eps: 0.227290
Reset
 25837/30000: episode: 213, duration: 1.090s, episode steps:  23, steps per second:  21, episode reward: 133.021, mean reward:  5.784 [-20.000, 21.683], mean action: 2.913 [1.000, 8.000],  loss: 27.283995, mae: 0.448621, mean_q: 0.792270, mean_eps: 0.225250
Reset
 25907/30000: episode: 214, duration: 1.597s, episode steps:  70, steps per second:  44, episode reward: 178.358, mean reward:  2.548 [-20.000, 30.294], mean action: 4.229 [0.000, 9.000],  loss: 22.058551, mae: 0.456445, mean_q: 0.813801, mean_eps: 0.223855
Reset
 25933/30000: episode: 215, duration: 0.358s, episode steps:  26, steps per second:  73, episode reward: 95.510, mean reward:  3.673 [-10.000, 18.579], mean action: 2.577 [1.000, 8.000],  loss: 22.110965, mae: 0.427836, mean_q: 0.804381, mean_eps: 0.222415
Reset
 25988/30000: episode: 216, duration: 1.329s, episode steps:  55, steps per second:  41, episode reward: 159.546, mean reward:  2.901 [-20.000, 19.064], mean action: 1.582 [0.000, 9.000],  loss: 25.579903, mae: 0.479560, mean_q: 0.808022, mean_eps: 0.221200
Reset
 26229/30000: episode: 217, duration: 3.497s, episode steps: 241, steps per second:  69, episode reward: -37.070, mean reward: -0.154 [-20.000, 25.250], mean action: 7.062 [0.000, 9.000],  loss: 25.598652, mae: 0.459052, mean_q: 0.810351, mean_eps: 0.216760
Reset
 26248/30000: episode: 218, duration: 0.367s, episode steps:  19, steps per second:  52, episode reward: 132.079, mean reward:  6.952 [-26.390, 15.323], mean action: 0.421 [0.000, 3.000],  loss: 21.532871, mae: 0.455127, mean_q: 0.815476, mean_eps: 0.212860
Reset
 26359/30000: episode: 219, duration: 1.660s, episode steps: 111, steps per second:  67, episode reward: 81.109, mean reward:  0.731 [-10.060, 28.089], mean action: 5.297 [0.000, 9.000],  loss: 21.346567, mae: 0.428814, mean_q: 0.808527, mean_eps: 0.210910
Reset
 26600/30000: episode: 220, duration: 3.452s, episode steps: 241, steps per second:  70, episode reward: -66.137, mean reward: -0.274 [-20.000, 23.684], mean action: 6.266 [0.000, 9.000],  loss: 23.705891, mae: 0.448042, mean_q: 0.816615, mean_eps: 0.205630
Reset
 26774/30000: episode: 221, duration: 1.899s, episode steps: 174, steps per second:  92, episode reward: -891.969, mean reward: -5.126 [-10.030, 31.933], mean action: 5.529 [0.000, 9.000],  loss: 22.525764, mae: 0.439062, mean_q: 0.827545, mean_eps: 0.199405
Reset
 27015/30000: episode: 222, duration: 4.899s, episode steps: 241, steps per second:  49, episode reward: 88.902, mean reward:  0.369 [-20.000, 50.288], mean action: 5.548 [0.000, 9.000],  loss: 22.470566, mae: 0.447137, mean_q: 0.808962, mean_eps: 0.193180
Reset
 27088/30000: episode: 223, duration: 1.734s, episode steps:  73, steps per second:  42, episode reward: 116.010, mean reward:  1.589 [-10.030, 20.505], mean action: 4.219 [1.000, 9.000],  loss: 22.447355, mae: 0.443820, mean_q: 0.796201, mean_eps: 0.188470
Reset
 27196/30000: episode: 224, duration: 1.870s, episode steps: 108, steps per second:  58, episode reward: 14.015, mean reward:  0.130 [-20.000, 88.506], mean action: 6.380 [0.000, 9.000],  loss: 28.490688, mae: 0.465886, mean_q: 0.805852, mean_eps: 0.185755
Reset
 27249/30000: episode: 225, duration: 1.048s, episode steps:  53, steps per second:  51, episode reward: 140.879, mean reward:  2.658 [-20.000, 89.727], mean action: 6.170 [0.000, 9.000],  loss: 23.682488, mae: 0.444951, mean_q: 0.806331, mean_eps: 0.183340
Reset
 27490/30000: episode: 226, duration: 3.965s, episode steps: 241, steps per second:  61, episode reward: 210.799, mean reward:  0.875 [-20.000, 23.410], mean action: 6.685 [0.000, 9.000],  loss: 28.901499, mae: 0.450894, mean_q: 0.807709, mean_eps: 0.178930
Reset
 27731/30000: episode: 227, duration: 4.314s, episode steps: 241, steps per second:  56, episode reward: 211.974, mean reward:  0.880 [-20.000, 101.854], mean action: 6.373 [0.000, 9.000],  loss: 26.751373, mae: 0.437377, mean_q: 0.803476, mean_eps: 0.171700
Reset
 27765/30000: episode: 228, duration: 0.958s, episode steps:  34, steps per second:  35, episode reward: 45.063, mean reward:  1.325 [-20.000, 28.180], mean action: 4.647 [0.000, 7.000],  loss: 25.492605, mae: 0.427184, mean_q: 0.802708, mean_eps: 0.167575
Reset
 28006/30000: episode: 229, duration: 4.206s, episode steps: 241, steps per second:  57, episode reward: 160.957, mean reward:  0.668 [-20.000, 103.524], mean action: 6.245 [0.000, 9.000],  loss: 23.764259, mae: 0.417124, mean_q: 0.787397, mean_eps: 0.163450
Reset
 28247/30000: episode: 230, duration: 4.188s, episode steps: 241, steps per second:  58, episode reward: 99.808, mean reward:  0.414 [-20.000, 54.416], mean action: 6.452 [0.000, 9.000],  loss: 23.492630, mae: 0.426894, mean_q: 0.792550, mean_eps: 0.156220
Reset
 28307/30000: episode: 231, duration: 0.945s, episode steps:  60, steps per second:  64, episode reward: 235.809, mean reward:  3.930 [-20.000, 197.148], mean action: 5.300 [0.000, 9.000],  loss: 26.491483, mae: 0.400587, mean_q: 0.789638, mean_eps: 0.151705
Reset
 28548/30000: episode: 232, duration: 3.583s, episode steps: 241, steps per second:  67, episode reward: 154.658, mean reward:  0.642 [-20.000, 24.614], mean action: 5.755 [0.000, 9.000],  loss: 27.010599, mae: 0.422125, mean_q: 0.791761, mean_eps: 0.147190
Reset
 28789/30000: episode: 233, duration: 4.113s, episode steps: 241, steps per second:  59, episode reward: 137.783, mean reward:  0.572 [-20.000, 28.571], mean action: 5.473 [0.000, 9.000],  loss: 33.783944, mae: 0.423370, mean_q: 0.792668, mean_eps: 0.139960
Reset
 28896/30000: episode: 234, duration: 2.545s, episode steps: 107, steps per second:  42, episode reward: 230.484, mean reward:  2.154 [-10.030, 54.606], mean action: 3.551 [0.000, 9.000],  loss: 31.087861, mae: 0.419308, mean_q: 0.784328, mean_eps: 0.134740
Reset
 29082/30000: episode: 235, duration: 1.620s, episode steps: 186, steps per second: 115, episode reward: -1418.294, mean reward: -7.625 [-21.667, 30.927], mean action: 2.032 [0.000, 9.000],  loss: 34.872308, mae: 0.422630, mean_q: 0.779989, mean_eps: 0.130345
Reset
 29192/30000: episode: 236, duration: 2.116s, episode steps: 110, steps per second:  52, episode reward: 105.911, mean reward:  0.963 [-20.000, 39.077], mean action: 6.855 [1.000, 9.000],  loss: 26.067159, mae: 0.424728, mean_q: 0.763078, mean_eps: 0.125905
Reset
 29433/30000: episode: 237, duration: 4.302s, episode steps: 241, steps per second:  56, episode reward: 246.868, mean reward:  1.024 [-20.000, 21.912], mean action: 5.527 [0.000, 9.000],  loss: 22.695207, mae: 0.411224, mean_q: 0.779864, mean_eps: 0.120640
Reset
 29674/30000: episode: 238, duration: 3.076s, episode steps: 241, steps per second:  78, episode reward: 227.870, mean reward:  0.946 [-20.000, 12.272], mean action: 6.158 [0.000, 9.000],  loss: 26.923304, mae: 0.407150, mean_q: 0.782612, mean_eps: 0.113410
Reset
 29767/30000: episode: 239, duration: 1.554s, episode steps:  93, steps per second:  60, episode reward: 70.004, mean reward:  0.753 [-20.000, 19.257], mean action: 6.151 [0.000, 9.000],  loss: 23.167078, mae: 0.407828, mean_q: 0.786828, mean_eps: 0.108400
Reset
 29790/30000: episode: 240, duration: 0.291s, episode steps:  23, steps per second:  79, episode reward: 149.951, mean reward:  6.520 [-20.000, 78.690], mean action: 3.217 [0.000, 5.000],  loss: 25.625263, mae: 0.408936, mean_q: 0.769006, mean_eps: 0.106660
Reset
 29825/30000: episode: 241, duration: 1.166s, episode steps:  35, steps per second:  30, episode reward: 121.508, mean reward:  3.472 [-41.045, 23.384], mean action: 2.514 [0.000, 4.000],  loss: 21.224479, mae: 0.391721, mean_q: 0.766597, mean_eps: 0.105790
Reset
done, took 561.818 seconds
Reset
Testing for 100 episodes ...
Reset
Episode 1: reward: 194.639, steps: 23
Reset
Episode 2: reward: 216.621, steps: 89
Reset
Episode 3: reward: 380.106, steps: 241
Reset
Episode 4: reward: 364.574, steps: 241
Reset
Episode 5: reward: 272.747, steps: 241
Reset
Episode 6: reward: 366.024, steps: 241
Reset
Episode 7: reward: 330.121, steps: 241
Reset
Episode 8: reward: 384.910, steps: 241
Reset
Episode 9: reward: 338.217, steps: 241
Reset
Episode 10: reward: -1012.149, steps: 241
Reset
Episode 11: reward: 218.768, steps: 53
Reset
Episode 12: reward: 276.394, steps: 241
Reset
Episode 13: reward: 239.469, steps: 78
Reset
Episode 14: reward: 143.171, steps: 12
Reset
Episode 15: reward: -2187.259, steps: 241
Reset
Episode 16: reward: 303.829, steps: 110
Reset
Episode 17: reward: 266.681, steps: 51
Reset
Episode 18: reward: 171.467, steps: 46
Reset
Episode 19: reward: 325.444, steps: 241
Reset
Episode 20: reward: -333.883, steps: 241
Reset
Episode 21: reward: 166.400, steps: 61
Reset
Episode 22: reward: -964.734, steps: 241
Reset
Episode 23: reward: 138.164, steps: 65
Reset
Episode 24: reward: -114.864, steps: 241
Reset
Episode 25: reward: 245.404, steps: 143
Reset
Episode 26: reward: 161.610, steps: 162
Reset
Episode 27: reward: 306.539, steps: 218
Reset
Episode 28: reward: 299.529, steps: 152
Reset
Episode 29: reward: 182.925, steps: 29
Reset
Episode 30: reward: 461.117, steps: 241
Reset
Episode 31: reward: 317.493, steps: 173
Reset
Episode 32: reward: 361.542, steps: 241
Reset
Episode 33: reward: -55.426, steps: 241
Reset
Episode 34: reward: 452.533, steps: 241
Reset
Episode 35: reward: -1405.936, steps: 241
Reset
Episode 36: reward: 220.555, steps: 85
Reset
Episode 37: reward: 279.984, steps: 241
Reset
Episode 38: reward: 333.126, steps: 217
Reset
Episode 39: reward: 271.542, steps: 102
Reset
Episode 40: reward: 172.545, steps: 63
Reset
Episode 41: reward: 71.638, steps: 241
Reset
Episode 42: reward: -900.758, steps: 241
Reset
Episode 43: reward: 366.458, steps: 241
Reset
Episode 44: reward: 311.149, steps: 157
Reset
Episode 45: reward: 228.477, steps: 123
Reset
Episode 46: reward: 400.641, steps: 241
Reset
Episode 47: reward: 135.715, steps: 37
Reset
Episode 48: reward: -1187.941, steps: 241
Reset
Episode 49: reward: 161.448, steps: 99
Reset
Episode 50: reward: -75.222, steps: 241
Reset
Episode 51: reward: 135.535, steps: 49
Reset
Episode 52: reward: -384.482, steps: 241
Reset
Episode 53: reward: 304.565, steps: 153
Reset
Episode 54: reward: 364.077, steps: 241
Reset
Episode 55: reward: 347.037, steps: 241
Reset
Episode 56: reward: 122.424, steps: 39
Reset
Episode 57: reward: 344.899, steps: 241
Reset
Episode 58: reward: 380.225, steps: 241
Reset
Episode 59: reward: -78.963, steps: 241
Reset
Episode 60: reward: 180.287, steps: 30
Reset
Episode 61: reward: 230.969, steps: 176
Reset
Episode 62: reward: 373.101, steps: 241
Reset
Episode 63: reward: 447.286, steps: 226
Reset
Episode 64: reward: 248.068, steps: 122
Reset
Episode 65: reward: 377.519, steps: 241
Reset
Episode 66: reward: 203.449, steps: 66
Reset
Episode 67: reward: 288.234, steps: 176
Reset
Episode 68: reward: 215.987, steps: 27
Reset
Episode 69: reward: 349.872, steps: 241
Reset
Episode 70: reward: 205.810, steps: 122
Reset
Episode 71: reward: -1975.458, steps: 241
Reset
Episode 72: reward: 287.750, steps: 231
Reset
Episode 73: reward: 330.971, steps: 241
Reset
Episode 74: reward: 144.715, steps: 11
Reset
Episode 75: reward: 395.639, steps: 241
Reset
Episode 76: reward: 266.342, steps: 122
Reset
Episode 77: reward: 180.248, steps: 62
Reset
Episode 78: reward: 282.865, steps: 124
Reset
Episode 79: reward: 308.097, steps: 218
Reset
Episode 80: reward: 340.261, steps: 241
Reset
Episode 81: reward: 231.241, steps: 178
Reset
Episode 82: reward: 373.070, steps: 241
Reset
Episode 83: reward: 239.848, steps: 126
Reset
Episode 84: reward: 176.155, steps: 95
Reset
Episode 85: reward: -477.699, steps: 101
Reset
Episode 86: reward: 372.621, steps: 126
Reset
Episode 87: reward: 158.511, steps: 53
Reset
Episode 88: reward: -2.314, steps: 18
Reset
Episode 89: reward: 392.303, steps: 241
Reset
Episode 90: reward: 316.968, steps: 204
Reset
Episode 91: reward: 320.112, steps: 149
Reset
Episode 92: reward: 369.523, steps: 241
Reset
Episode 93: reward: 381.120, steps: 241
Reset
Episode 94: reward: 209.503, steps: 105
Reset
Episode 95: reward: 22.258, steps: 35
Reset
Episode 96: reward: 410.539, steps: 241
Reset
Episode 97: reward: 403.055, steps: 241
Reset
Episode 98: reward: 302.310, steps: 218
Reset
Episode 99: reward: 173.034, steps: 131
Reset
Episode 100: reward: 79.796, steps: 11
122.7082844895616
Reset
Reset
(20, 242)
